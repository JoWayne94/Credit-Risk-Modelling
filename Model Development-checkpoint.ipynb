{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import uniform\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\tjowayne\\Desktop\\Model\\credit_card.csv')\n",
    "df = df.drop(columns=['ID'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create dummy variables with only two values '''\n",
    "df1= pd.get_dummies(df, columns=['EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6'], \n",
    "                    prefix= ['EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6'])\n",
    "df1.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('default.payment.next.month', axis=1)\n",
    "y = df1['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Imbalance Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_no_default = len(df[df['default.payment.next.month']==0])\n",
    "count_default = len(df[df['default.payment.next.month']==1])\n",
    "pct_of_no_default = count_no_default / (count_no_default + count_default)\n",
    "print(\"percentage of no default is\", pct_of_no_default*100)\n",
    "pct_of_default = count_default / (count_no_default + count_default)\n",
    "print(\"percentage of default\", pct_of_default*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df1.loc[df1['default.payment.next.month'] == 1]))\n",
    "print(len(df1.loc[df1['default.payment.next.month'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Balanced Training Dataset\n",
    "test = df1.loc[df1['default.payment.next.month'] == 1].sample(n=500,random_state=7)\n",
    "test = test.append(df1.loc[df1['default.payment.next.month'] == 0].sample(n=500,random_state=7), sort=False)\n",
    "test = test.sample(frac=1, random_state=14)\n",
    "train = df1.drop(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating input features and target variables\n",
    "X_train = train.loc[:, train.columns != 'default.payment.next.month']\n",
    "y_train = train.loc[:, train.columns == 'default.payment.next.month']\n",
    "X_test = test.loc[:, test.columns != 'default.payment.next.month']\n",
    "y_test = test.loc[:, test.columns == 'default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = df1.loc[df1['default.payment.next.month'] == 1].sample(n=3680,random_state=7)\n",
    "# train = train.append(df1.loc[df1['default.payment.next.month'] == 0].sample(n=3680,random_state=7),sort=False)\n",
    "# train = train.sample(frac=1, random_state=7)\n",
    "# test = df1.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = np.array(X_train)\n",
    "y_train_sm = np.array(y_train)\n",
    "columns = X_train.columns\n",
    "\n",
    "os = SMOTE(random_state=7)\n",
    "X_train_res, y_train_res = os.fit_sample(X_train_sm, y_train_sm.ravel())\n",
    "\n",
    "# we can Check the numbers of our data\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train_sm==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train_sm==0)))\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "\n",
    "X_train_res = pd.DataFrame(data=X_train_res, columns=columns )\n",
    "y_train_res= pd.DataFrame(data=y_train_res, columns=['default.payment.next.month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns:\n",
    "    X_train_res[i] = X_train_res[i].astype(X_train[i].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Feature importance function '''\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing(df, col, name, na_dict):\n",
    "    if is_numeric_dtype(col):\n",
    "        if pd.isnull(col).sum() or (name in na_dict):\n",
    "            df[name+'_na'] = pd.isnull(col)\n",
    "            filler = na_dict[name] if name in na_dict else col.median()\n",
    "            df[name] = col.fillna(filler)\n",
    "            na_dict[name] = filler\n",
    "    return na_dict\n",
    "\n",
    "def numericalize(df, col, name, max_n_cat):\n",
    "    if not is_numeric_dtype(col) and ( max_n_cat is None or len(col.cat.categories)>max_n_cat):\n",
    "        df[name] = pd.Categorical(col).codes+1\n",
    "\n",
    "def proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n",
    "            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n",
    "    if not ignore_flds: ignore_flds=[]\n",
    "    if not skip_flds: skip_flds=[]\n",
    "    if subset: df = get_sample(df,subset)\n",
    "    else: df = df.copy()\n",
    "    ignored_flds = df.loc[:, ignore_flds]\n",
    "    df.drop(ignore_flds, axis=1, inplace=True)\n",
    "    if preproc_fn: preproc_fn(df)\n",
    "    if y_fld is None: y = None\n",
    "    else:\n",
    "        if not is_numeric_dtype(df[y_fld]): df[y_fld] = pd.Categorical(df[y_fld]).codes\n",
    "        y = df[y_fld].values\n",
    "        skip_flds += [y_fld]\n",
    "    df.drop(skip_flds, axis=1, inplace=True)\n",
    "\n",
    "    if na_dict is None: na_dict = {}\n",
    "    else: na_dict = na_dict.copy()\n",
    "    na_dict_initial = na_dict.copy()\n",
    "    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n",
    "    if len(na_dict_initial.keys()) > 0:\n",
    "        df.drop([a + '_na' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis=1, inplace=True)\n",
    "    if do_scale: mapper = scale_vars(df, mapper)\n",
    "    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n",
    "    df = pd.get_dummies(df, dummy_na=True)\n",
    "    df = pd.concat([ignored_flds, df], axis=1)\n",
    "    res = [df, y, na_dict]\n",
    "    if do_scale: res = res + [mapper]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Impute the missing values and store the data as dependent and independent part '''\n",
    "df_trn, y_trn, nas = proc_df(df1, 'default.payment.next.month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf = X_train\n",
    "y_train_rf = y_train\n",
    "X_test_rf = X_test\n",
    "y_test_rf = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_rf, y_train_rf)\n",
    "# Predictions\n",
    "rfc_predict = rfc.predict(X_test_rf)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Top 10 most important features for our current model '''\n",
    "fi = rf_feat_importance(rfc, df_trn)\n",
    "fi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Build a random forest model using only the features that have a feature importance greater than 0.005 '''\n",
    "to_keep = fi[fi.imp>0.05].cols\n",
    "X_train_rf = X_train_rf[to_keep.values]\n",
    "X_test_rf = X_test_rf[to_keep.values]\n",
    "print(len(to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1400, stop = 1800, num = 3)]\n",
    "\n",
    "# number of features at every split\n",
    "max_features = ['sqrt'] # 'auto'\n",
    "\n",
    "# max depth\n",
    "# max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
    "# max_depth.append(None)\n",
    "max_depth = [int(x) for x in np.linspace(420, 500, num = 3)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# minimum number of samples required to be at a leaf node\n",
    "min_samples_leaf = [int(x) for x in np.linspace(3, 5, 3, endpoint=True)]\n",
    "\n",
    "# Whether to use out-of-bag samples to estimate the generalization accuracy\n",
    "oob_score = [True]\n",
    "\n",
    "# minimum number of samples required to split an internal node\n",
    "# min_samples_split = [x for x in np.linspace(0.1, 1.0, 10, endpoint=True)]\n",
    "\n",
    "# create random grid\n",
    "random_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth, \n",
    "               'min_samples_leaf': min_samples_leaf, 'oob_score': oob_score}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=14, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Grid search of parameters\n",
    "rfc_grid = GridSearchCV(estimator = rfc, param_grid = random_grid, cv = cv.split(X_train_rf, y_train_rf),\n",
    "                        verbose=5, n_jobs=-1)\n",
    "# Fit the model\n",
    "rfc_grid.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# print results\n",
    "print(rfc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_taken/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug values back into the model to see if it improved our performance\n",
    "rfc = RandomForestClassifier(n_estimators = 1400, min_samples_leaf = 5, max_features = 'sqrt', max_depth = 420,\n",
    "                             oob_score = True)\n",
    "rfc.fit(X_train_rf, y_train_rf)\n",
    "rfc_predict = rfc.predict(X_test_rf)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=5, scoring='roc_auc')\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test_rf, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test_rf, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lg = X_train_res\n",
    "y_train_lg = y_train_res\n",
    "X_test_lg = X_test\n",
    "y_test_lg = y_test\n",
    "\n",
    "log = df1.loc[df1['default.payment.next.month'] == 1].sample(n=5200,random_state=7)\n",
    "log = log.append(df1.loc[df1['default.payment.next.month'] == 0].sample(n=5200,random_state=7),sort=False)\n",
    "log = log.sample(frac=1, random_state=7)\n",
    "X_log = log.drop('default.payment.next.month', axis=1)\n",
    "y_log = log['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(X_log, y_log.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df1.columns.values[np.where(rfe.support_ == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log1 = X_log[cols]\n",
    "logit_model=sm.Logit(y_log, X_log1)\n",
    "result=logit_model.fit(method='bfgs', maxiter=1000)\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variables with p-values larger than 0.05\n",
    "cols = ['EDUCATION_3', 'PAY_0_1', 'PAY_0_2', 'PAY_0_3', 'PAY_0_8', 'PAY_2_2', 'PAY_2_3', 'PAY_3_2',\n",
    "        'PAY_3_3', 'PAY_5_2', 'PAY_5_3']\n",
    "X_log2 = X_log[cols]\n",
    "logit_model=sm.Logit(y_log, X_log2)\n",
    "result=logit_model.fit(method='bfgs', maxiter=1000)\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lg = X_train_lg[cols]\n",
    "X_test_lg = X_test_lg[cols]\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_lg, y_train_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "# C = uniform(loc=0, scale=4)\n",
    "C = np.logspace(-3,3,7)\n",
    "\n",
    "fit_intercept = [True, False]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, fit_intercept=fit_intercept, penalty=penalty)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=14, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Create grid search 10-fold cross validation\n",
    "clf = GridSearchCV(estimator = logreg, param_grid = hyperparameters, cv = cv.split(X_train_lg, y_train_lg),\n",
    "                   verbose=5, n_jobs=-1)\n",
    "# Fit randomized search\n",
    "best_model = clf.fit(X_train_lg, y_train_lg)\n",
    "\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best fit_intercept:', best_model.best_estimator_.get_params()['fit_intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_lg)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(best_model.score(X_test_lg, y_test_lg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test_lg, y_pred)\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix)\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test_lg, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test_lg, logreg.predict(X_test_lg))\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lg, logreg.predict_proba(X_test_lg)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = X_train_res\n",
    "y_train_nn = y_train_res\n",
    "X_test_nn = X_test\n",
    "y_test_nn = y_test\n",
    "\n",
    "cols = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "       'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical data -1 to 1\n",
    "scaler = StandardScaler()\n",
    "def scale_numerical(df,columns):\n",
    "    for column in columns:\n",
    "        df.loc[:,[column]] = scaler.fit_transform(df.loc[:,[column]])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing the input feature\n",
    "X_test_nn = scale_numerical(X_test_nn, cols)\n",
    "X_train_pca = scale_numerical(X_train_nn, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=74, random_state=7)\n",
    "pca.fit(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The amount of variance that each PC explains\n",
    "var = pca.explained_variance_ratio_\n",
    "print(var*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumulative Variance explains\n",
    "var1 = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print(var1)\n",
    "plt.plot(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=14)\n",
    "pca.fit(X_train_pca)\n",
    "X_train_pca1 = pca.fit_transform(X_train_pca)\n",
    "X_train_pca1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df = abs(pca.components_)\n",
    "components_df = pd.DataFrame(components_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dict = {}\n",
    "for i in range(len(components_df.columns)):\n",
    "    column_dict[i] = X_train_nn.columns[i]\n",
    "components_df.rename(columns=column_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = pca.explained_variance_ratio_\n",
    "components_df1 = components_df.copy()\n",
    "for col in components_df1.columns:\n",
    "    components_df1[col] = components_df1[col]*var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df['variance'] = var\n",
    "components_df.T.sort_values(by=0,ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weight = pd.DataFrame(components_df1.sum(axis=0)).reset_index()\n",
    "var_weight.rename(columns={'index':'feature',0:'variance_weight'},inplace=True)\n",
    "var_weight.sort_values(by='variance_weight',ascending=False,inplace=True)\n",
    "var_weight.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = var_weight.feature.head(14).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_nn = pca.transform(X_train_nn)\n",
    "# X_test_nn = pca.transform(X_test_nn)\n",
    "X_train_nn = X_train_pca[cols]\n",
    "X_test_nn = X_test_nn[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = X_train_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f1(y_true, y_pred):\n",
    "#     y_pred = K.round(y_pred)\n",
    "#     tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "#     tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "#     fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "#     fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "#     p = tp / (tp + fp + K.epsilon())\n",
    "#     r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "#     f1 = 2*p*r / (p+r+K.epsilon())\n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "#     return K.mean(f1)\n",
    "\n",
    "def f1(y_true, y_pred, beta=1, threshold=0.4):\n",
    "    \n",
    "    y_true = K.cast(y_true, 'float')\n",
    "    y_pred = K.cast(K.greater(K.cast(y_pred, 'float'), threshold), 'float')\n",
    "\n",
    "    tp = K.sum(y_true * y_pred, axis=0)\n",
    "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
    "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = (1 + beta ** 2) * p * r / ((beta ** 2) * p + r + K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(learn_rate=0.01, neurons=10):\n",
    "    classifier = Sequential()\n",
    "    #First Hidden Layer\n",
    "    classifier.add(Dense(neurons, activation='relu', kernel_initializer='random_uniform', input_dim=74))\n",
    "    #Second  Hidden Layer\n",
    "    # classifier.add(Dense(neurons, activation='relu', kernel_initializer='random_uniform'))\n",
    "    #Output Layer\n",
    "    classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_uniform'))\n",
    "    #Compiling the neural network\n",
    "    optimizer = optimizers.Adam(lr=learn_rate)\n",
    "    classifier.compile(optimizer=optimizer, loss=f1_loss, metrics =['accuracy', f1])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=build_classifier, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# epochs = [10, 50, 100]\n",
    "# learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "# neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "batch_size = [40, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "learn_rate = [0.01, 0.1, 0.3]\n",
    "neurons = [15, 20, 25]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, learn_rate=learn_rate, neurons=neurons)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=14, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = RandomizedSearchCV(estimator=classifier, param_distributions=param_grid, n_iter=10, random_state=7,\n",
    "#                           cv = cv.split(X_train_nn, y_train_nn), verbose=5, n_jobs=-1)\n",
    "# grid_result = grid.fit(X_train_nn, y_train_nn)\n",
    "grid = GridSearchCV(estimator=classifier, param_grid=param_grid, cv = cv.split(X_train_nn, y_train_nn),\n",
    "                    verbose=10, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train_nn, y_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_result.best_estimator_.predict(X_test_nn)\n",
    "print('Accuracy of neural net on test set: {:.2f}'.format(grid_result.best_estimator_.score(X_test_nn, y_test_nn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test_nn, y_pred)\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix)\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test_nn, y_pred))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
